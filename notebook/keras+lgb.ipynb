{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c360690c-e2cb-4a0e-9614-26c9e591e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1598ccb-71cb-4dcf-b901-ba5e99a74fb0",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e51dc310-2ddb-43fb-900e-37fdb385bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"text_id\")\n",
    "X_train = train_df.full_text\n",
    "cols = [col for col in train_df.columns if col != \"full_text\"]\n",
    "y_train = train_df[cols]\n",
    "X_test = pd.read_csv(\"../input/test.csv\", index_col=\"text_id\").full_text\n",
    "X_test_idx = X_test.index\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_matrix(X_train, \"tfidf\")\n",
    "X_test = tokenizer.texts_to_matrix(X_test, \"tfidf\")\n",
    "\n",
    "pca = PCA(n_components=100, whiten=True, random_state=seed)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = tts(X_train, y_train, test_size=.1, random_state=seed)\n",
    "\n",
    "lgb_trains = {}\n",
    "lgb_vals = {}\n",
    "for col in cols:\n",
    "    exec(f\"lgb_trains['{col}'] = lgb.Dataset(X_train, y_train.{col})\")\n",
    "    exec(f\"lgb_vals['{col}'] = lgb.Dataset(X_val, y_val.{col})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580baa2a-cf71-4c80-a0a4-d5250c7cd2a9",
   "metadata": {},
   "source": [
    "# Custom Loss Function - MCRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3140d2a-3168-4afb-bb3a-09bcab320767",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def MCRMSE_keras(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.reduce_mean(tf.square(y_true - y_pred), axis=1))\n",
    "\n",
    "def MCRMSE_lgb(preds, eval_data):\n",
    "    diff = eval_data - preds\n",
    "    sq = np.square(diff)\n",
    "    rmse = np.sum(sq, axis=0) / eval_data.shape[0]\n",
    "    return \"MCRMSE\", np.sum(rmse) / eval_data.shape[1], False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893efe9-1a9e-4795-b2b5-21c2fe0f94fd",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26641966-7fe7-4459-9cb7-ff2928438705",
   "metadata": {},
   "source": [
    "## keras 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10ee71c5-8868-4d2a-adf5-3869aede75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "440/440 [==============================] - 4s 7ms/step - loss: 0.3889 - MCRMSE_keras: 0.3889 - val_loss: 0.3358 - val_MCRMSE_keras: 0.3358\n",
      "Epoch 2/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.3034 - MCRMSE_keras: 0.3034 - val_loss: 0.3581 - val_MCRMSE_keras: 0.3581\n",
      "Epoch 3/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2858 - MCRMSE_keras: 0.2858 - val_loss: 0.3242 - val_MCRMSE_keras: 0.3242\n",
      "Epoch 4/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2644 - MCRMSE_keras: 0.2644 - val_loss: 0.3391 - val_MCRMSE_keras: 0.3391\n",
      "Epoch 5/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2522 - MCRMSE_keras: 0.2522 - val_loss: 0.3531 - val_MCRMSE_keras: 0.3531\n",
      "Epoch 6/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2387 - MCRMSE_keras: 0.2387 - val_loss: 0.3458 - val_MCRMSE_keras: 0.3458\n",
      "Epoch 7/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2216 - MCRMSE_keras: 0.2216 - val_loss: 0.3608 - val_MCRMSE_keras: 0.3608\n",
      "Epoch 8/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.2127 - MCRMSE_keras: 0.2127 - val_loss: 0.3821 - val_MCRMSE_keras: 0.3821\n",
      "Epoch 9/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1997 - MCRMSE_keras: 0.1997 - val_loss: 0.3528 - val_MCRMSE_keras: 0.3528\n",
      "Epoch 10/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1949 - MCRMSE_keras: 0.1949 - val_loss: 0.3546 - val_MCRMSE_keras: 0.3546\n",
      "Epoch 11/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1851 - MCRMSE_keras: 0.1852 - val_loss: 0.3657 - val_MCRMSE_keras: 0.3657\n",
      "Epoch 12/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1825 - MCRMSE_keras: 0.1825 - val_loss: 0.3593 - val_MCRMSE_keras: 0.3593\n",
      "Epoch 13/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1748 - MCRMSE_keras: 0.1748 - val_loss: 0.3780 - val_MCRMSE_keras: 0.3780\n",
      "Epoch 14/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1769 - MCRMSE_keras: 0.1769 - val_loss: 0.3495 - val_MCRMSE_keras: 0.3495\n",
      "Epoch 15/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1665 - MCRMSE_keras: 0.1665 - val_loss: 0.3742 - val_MCRMSE_keras: 0.3742\n",
      "Epoch 16/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1623 - MCRMSE_keras: 0.1623 - val_loss: 0.3934 - val_MCRMSE_keras: 0.3934\n",
      "Epoch 17/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1588 - MCRMSE_keras: 0.1588 - val_loss: 0.3751 - val_MCRMSE_keras: 0.3751\n",
      "Epoch 18/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1499 - MCRMSE_keras: 0.1499 - val_loss: 0.3853 - val_MCRMSE_keras: 0.3853\n",
      "Epoch 19/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1524 - MCRMSE_keras: 0.1524 - val_loss: 0.3673 - val_MCRMSE_keras: 0.3673\n",
      "Epoch 20/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1460 - MCRMSE_keras: 0.1460 - val_loss: 0.3592 - val_MCRMSE_keras: 0.3592\n",
      "Epoch 21/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1445 - MCRMSE_keras: 0.1445 - val_loss: 0.3721 - val_MCRMSE_keras: 0.3721\n",
      "Epoch 22/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1374 - MCRMSE_keras: 0.1374 - val_loss: 0.3680 - val_MCRMSE_keras: 0.3680\n",
      "Epoch 23/30\n",
      "440/440 [==============================] - 3s 8ms/step - loss: 0.1358 - MCRMSE_keras: 0.1358 - val_loss: 0.3704 - val_MCRMSE_keras: 0.3704\n",
      "Epoch 24/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1390 - MCRMSE_keras: 0.1390 - val_loss: 0.3646 - val_MCRMSE_keras: 0.3646\n",
      "Epoch 25/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1321 - MCRMSE_keras: 0.1321 - val_loss: 0.3789 - val_MCRMSE_keras: 0.3789\n",
      "Epoch 26/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1313 - MCRMSE_keras: 0.1313 - val_loss: 0.3670 - val_MCRMSE_keras: 0.3670\n",
      "Epoch 27/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1255 - MCRMSE_keras: 0.1255 - val_loss: 0.3678 - val_MCRMSE_keras: 0.3678\n",
      "Epoch 28/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1238 - MCRMSE_keras: 0.1239 - val_loss: 0.3678 - val_MCRMSE_keras: 0.3678\n",
      "Epoch 29/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1238 - MCRMSE_keras: 0.1238 - val_loss: 0.3734 - val_MCRMSE_keras: 0.3734\n",
      "Epoch 30/30\n",
      "440/440 [==============================] - 3s 7ms/step - loss: 0.1210 - MCRMSE_keras: 0.1210 - val_loss: 0.3793 - val_MCRMSE_keras: 0.3793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86940b2fa0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000C359D63E</th>\n",
       "      <td>3.038789</td>\n",
       "      <td>2.525820</td>\n",
       "      <td>3.111001</td>\n",
       "      <td>2.971141</td>\n",
       "      <td>2.554483</td>\n",
       "      <td>2.692028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000BAD50D026</th>\n",
       "      <td>2.906303</td>\n",
       "      <td>2.725901</td>\n",
       "      <td>2.728677</td>\n",
       "      <td>2.433096</td>\n",
       "      <td>2.416244</td>\n",
       "      <td>2.971677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00367BB2546B</th>\n",
       "      <td>4.091075</td>\n",
       "      <td>3.592160</td>\n",
       "      <td>3.719064</td>\n",
       "      <td>3.751686</td>\n",
       "      <td>3.624677</td>\n",
       "      <td>3.804587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "text_id                                                               \n",
       "0000C359D63E  3.038789  2.525820    3.111001     2.971141  2.554483   \n",
       "000BAD50D026  2.906303  2.725901    2.728677     2.433096  2.416244   \n",
       "00367BB2546B  4.091075  3.592160    3.719064     3.751686  3.624677   \n",
       "\n",
       "              conventions  \n",
       "text_id                    \n",
       "0000C359D63E     2.692028  \n",
       "000BAD50D026     2.971677  \n",
       "00367BB2546B     3.804587  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras1_model = Sequential()\n",
    "keras1_model.add(Dense(500, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "keras1_model.add(BatchNormalization())\n",
    "keras1_model.add(Dense(500, activation=\"relu\"))\n",
    "keras1_model.add(Dropout(.3))\n",
    "keras1_model.add(Dense(500, activation=LeakyReLU(.1)))\n",
    "keras1_model.add(Dropout(.2))\n",
    "keras1_model.add(Dense(500, activation=\"relu\"))\n",
    "keras1_model.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "keras1_model.add(Rescaling(4, offset=1))\n",
    "\n",
    "optimizer = optimizers.Adam(amsgrad=True)\n",
    "keras1_model.compile(loss=MCRMSE_keras, optimizer=optimizer, metrics=[MCRMSE_keras])\n",
    "keras1_model.fit(X_train, y_train, batch_size=2**3, epochs=30, verbose=1,\n",
    "          validation_data=(X_val, y_val), workers=30, use_multiprocessing=True,\n",
    "          callbacks=[EarlyStopping(monitor=\"loss\", patience=3, restore_best_weights=True)])\n",
    "\n",
    "keras1_pred = pd.DataFrame(keras1_model.predict(X_test), columns=cols, index=X_test_idx)\n",
    "keras1_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b84966-61f2-4db9-8fe8-787f6d4451c8",
   "metadata": {},
   "source": [
    "## keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7a2c834-b802-44e1-993e-2118c6784ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "440/440 [==============================] - 8s 14ms/step - loss: 0.4625 - MCRMSE: 0.4625 - val_loss: 1.1395 - val_MCRMSE: 1.1395\n",
      "Epoch 2/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3793 - MCRMSE: 0.3793 - val_loss: 0.7027 - val_MCRMSE: 0.7027\n",
      "Epoch 3/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3752 - MCRMSE: 0.3752 - val_loss: 0.3889 - val_MCRMSE: 0.3889\n",
      "Epoch 4/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3447 - MCRMSE: 0.3448 - val_loss: 0.4141 - val_MCRMSE: 0.4141\n",
      "Epoch 5/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3496 - MCRMSE: 0.3496 - val_loss: 0.3624 - val_MCRMSE: 0.3624\n",
      "Epoch 6/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3356 - MCRMSE: 0.3357 - val_loss: 0.3778 - val_MCRMSE: 0.3778\n",
      "Epoch 7/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3335 - MCRMSE: 0.3335 - val_loss: 0.3514 - val_MCRMSE: 0.3514\n",
      "Epoch 8/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3218 - MCRMSE: 0.3218 - val_loss: 0.3665 - val_MCRMSE: 0.3665\n",
      "Epoch 9/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.3072 - MCRMSE: 0.3072 - val_loss: 0.3584 - val_MCRMSE: 0.3584\n",
      "Epoch 10/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2946 - MCRMSE: 0.2945 - val_loss: 0.3747 - val_MCRMSE: 0.3747\n",
      "Epoch 11/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2963 - MCRMSE: 0.2963 - val_loss: 0.3913 - val_MCRMSE: 0.3913\n",
      "Epoch 12/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2906 - MCRMSE: 0.2905 - val_loss: 0.3799 - val_MCRMSE: 0.3799\n",
      "Epoch 13/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2802 - MCRMSE: 0.2802 - val_loss: 0.3501 - val_MCRMSE: 0.3501\n",
      "Epoch 14/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2675 - MCRMSE: 0.2676 - val_loss: 0.3785 - val_MCRMSE: 0.3785\n",
      "Epoch 15/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2692 - MCRMSE: 0.2692 - val_loss: 0.3650 - val_MCRMSE: 0.3650\n",
      "Epoch 16/30\n",
      "440/440 [==============================] - 6s 14ms/step - loss: 0.2561 - MCRMSE: 0.2560 - val_loss: 0.4012 - val_MCRMSE: 0.4012\n",
      "Epoch 17/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2517 - MCRMSE: 0.2517 - val_loss: 0.3844 - val_MCRMSE: 0.3844\n",
      "Epoch 18/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2454 - MCRMSE: 0.2453 - val_loss: 0.3684 - val_MCRMSE: 0.3684\n",
      "Epoch 19/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2414 - MCRMSE: 0.2414 - val_loss: 0.4021 - val_MCRMSE: 0.4021\n",
      "Epoch 20/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2468 - MCRMSE: 0.2468 - val_loss: 0.3541 - val_MCRMSE: 0.3541\n",
      "Epoch 21/30\n",
      "440/440 [==============================] - 6s 14ms/step - loss: 0.2382 - MCRMSE: 0.2382 - val_loss: 0.3645 - val_MCRMSE: 0.3645\n",
      "Epoch 22/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2270 - MCRMSE: 0.2270 - val_loss: 0.3558 - val_MCRMSE: 0.3558\n",
      "Epoch 23/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2394 - MCRMSE: 0.2394 - val_loss: 0.3626 - val_MCRMSE: 0.3626\n",
      "Epoch 24/30\n",
      "440/440 [==============================] - 6s 14ms/step - loss: 0.2234 - MCRMSE: 0.2234 - val_loss: 0.3469 - val_MCRMSE: 0.3469\n",
      "Epoch 25/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2285 - MCRMSE: 0.2285 - val_loss: 0.3699 - val_MCRMSE: 0.3699\n",
      "Epoch 26/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2227 - MCRMSE: 0.2226 - val_loss: 0.3595 - val_MCRMSE: 0.3595\n",
      "Epoch 27/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2125 - MCRMSE: 0.2125 - val_loss: 0.3962 - val_MCRMSE: 0.3962\n",
      "Epoch 28/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2127 - MCRMSE: 0.2127 - val_loss: 0.3602 - val_MCRMSE: 0.3602\n",
      "Epoch 29/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2136 - MCRMSE: 0.2136 - val_loss: 0.3772 - val_MCRMSE: 0.3772\n",
      "Epoch 30/30\n",
      "440/440 [==============================] - 6s 13ms/step - loss: 0.2171 - MCRMSE: 0.2171 - val_loss: 0.3707 - val_MCRMSE: 0.3707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85621b51f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000C359D63E</th>\n",
       "      <td>2.991902</td>\n",
       "      <td>2.925776</td>\n",
       "      <td>3.117795</td>\n",
       "      <td>2.986269</td>\n",
       "      <td>2.844204</td>\n",
       "      <td>2.960994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000BAD50D026</th>\n",
       "      <td>3.017218</td>\n",
       "      <td>2.951318</td>\n",
       "      <td>3.138716</td>\n",
       "      <td>3.013410</td>\n",
       "      <td>2.878500</td>\n",
       "      <td>2.985172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00367BB2546B</th>\n",
       "      <td>3.739797</td>\n",
       "      <td>3.693804</td>\n",
       "      <td>3.748791</td>\n",
       "      <td>3.783935</td>\n",
       "      <td>3.856252</td>\n",
       "      <td>3.687125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "text_id                                                               \n",
       "0000C359D63E  2.991902  2.925776    3.117795     2.986269  2.844204   \n",
       "000BAD50D026  3.017218  2.951318    3.138716     3.013410  2.878500   \n",
       "00367BB2546B  3.739797  3.693804    3.748791     3.783935  3.856252   \n",
       "\n",
       "              conventions  \n",
       "text_id                    \n",
       "0000C359D63E     2.960994  \n",
       "000BAD50D026     2.985172  \n",
       "00367BB2546B     3.687125  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras2_model = Sequential()\n",
    "keras2_model.add(Dense(2000, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "keras2_model.add(BatchNormalization())\n",
    "keras2_model.add(Dense(2000, activation=\"relu\"))\n",
    "keras2_model.add(Dropout(.3))\n",
    "keras2_model.add(Dense(3000, activation=LeakyReLU(.1)))\n",
    "keras2_model.add(Dropout(.2))\n",
    "keras2_model.add(Dense(2000, activation=\"relu\"))\n",
    "keras2_model.add(Dense(500, activation=\"relu\"))\n",
    "keras2_model.add(Dense(3000, activation=\"softplus\"))\n",
    "keras2_model.add(BatchNormalization())\n",
    "keras2_model.add(Dense(1000, activation=LeakyReLU(.1)))\n",
    "keras2_model.add(Dropout(.3))\n",
    "keras2_model.add(Dense(3000, activation=\"softsign\"))\n",
    "keras2_model.add(Dense(1000, activation=LeakyReLU(.1)))\n",
    "keras2_model.add(Dropout(.1))\n",
    "keras2_model.add(Dense(3000, activation=\"softplus\"))\n",
    "keras2_model.add(Dropout(.4))\n",
    "keras2_model.add(Dense(3000, activation=\"relu\"))\n",
    "keras2_model.add(Dense(1000, activation=\"relu\"))\n",
    "keras2_model.add(BatchNormalization())\n",
    "keras2_model.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "keras2_model.add(Rescaling(4, offset=1))\n",
    "\n",
    "optimizer = optimizers.Adam(amsgrad=True)\n",
    "keras2_model.compile(loss=MCRMSE_keras, optimizer=optimizer, metrics=[MCRMSE_keras])\n",
    "keras2_model.fit(X_train, y_train, batch_size=2**3, epochs=50, verbose=1,\n",
    "          validation_data=(X_val, y_val), workers=30, use_multiprocessing=True,\n",
    "          callbacks=[EarlyStopping(monitor=\"loss\", patience=3, restore_best_weights=True)])\n",
    "\n",
    "keras2_pred = pd.DataFrame(keras2_model.predict(X_test), columns=cols, index=X_test_idx)\n",
    "keras2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00431e96-41a9-46d0-93f8-4b4c6b398839",
   "metadata": {},
   "source": [
    "## lgb 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91623fbd-7ee7-46c1-8642-bb4a601275f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.229601\tvalid_1's rmse: 0.604431\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 0.288907\tvalid_1's rmse: 0.598802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.228208\tvalid_1's rmse: 0.555123\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 0.286076\tvalid_1's rmse: 0.548253\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 0.322176\tvalid_1's rmse: 0.498272\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.229137\tvalid_1's rmse: 0.556112\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's rmse: 0.283216\tvalid_1's rmse: 0.55231\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.249628\tvalid_1's rmse: 0.618543\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 0.346478\tvalid_1's rmse: 0.612825\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.382837\tvalid_1's rmse: 0.605135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000C359D63E</th>\n",
       "      <td>3.011834</td>\n",
       "      <td>2.909469</td>\n",
       "      <td>3.166960</td>\n",
       "      <td>2.825631</td>\n",
       "      <td>2.714723</td>\n",
       "      <td>2.622996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000BAD50D026</th>\n",
       "      <td>3.220171</td>\n",
       "      <td>2.851266</td>\n",
       "      <td>3.033757</td>\n",
       "      <td>3.006670</td>\n",
       "      <td>2.572265</td>\n",
       "      <td>3.079148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00367BB2546B</th>\n",
       "      <td>3.847193</td>\n",
       "      <td>3.421739</td>\n",
       "      <td>3.666559</td>\n",
       "      <td>3.480376</td>\n",
       "      <td>3.541353</td>\n",
       "      <td>3.499535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "text_id                                                               \n",
       "0000C359D63E  3.011834  2.909469    3.166960     2.825631  2.714723   \n",
       "000BAD50D026  3.220171  2.851266    3.033757     3.006670  2.572265   \n",
       "00367BB2546B  3.847193  3.421739    3.666559     3.480376  3.541353   \n",
       "\n",
       "              conventions  \n",
       "text_id                    \n",
       "0000C359D63E     2.622996  \n",
       "000BAD50D026     3.079148  \n",
       "00367BB2546B     3.499535  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb1_models = {}\n",
    "lgb1_preds = {}\n",
    "\n",
    "for score in cols:\n",
    "    lgb1_params = {'objective': 'regression',\n",
    "                   'metric': 'rmse',\n",
    "                   'verbosity': 0,\n",
    "                   'early_stopping_round': 50,\n",
    "                   'random_state': seed,\n",
    "                   'device': 'gpu'}\n",
    "    \n",
    "    train_set=lgb_trains[score]\n",
    "    valid_sets=lgb_vals[score]\n",
    "\n",
    "    lgb1_model = lgb.train(\n",
    "        params=lgb1_params,\n",
    "        train_set=train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=(train_set, valid_sets),\n",
    "        callbacks=None,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    lgb1_models[score] = lgb1_model\n",
    "    lgb1_preds[score] = lgb1_model.predict(X_test)\n",
    "    \n",
    "lgb1_pred = pd.DataFrame(lgb1_preds, index=X_test_idx)\n",
    "lgb1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf071bc8-1ae0-4465-aaab-f6a70122398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(np.mean(np.array([keras1_pred, keras2_pred, lgb1_pred]), axis=0), columns=cols, index=X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae45bbc1-e9b1-42da-8fb9-35500d5572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(\"submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b6f7c-2a25-4338-8b24-e69072c12474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
